{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandini-55/AI-Machine_Learning_Journey/blob/main/Unsupervised%20Machine%20Learning/CNN_irisDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8hBvhFSktfK2"
      },
      "outputs": [],
      "source": [
        "#Import & setup\n",
        "import numpy as np   # Numerical arrays +RNG seeding\n",
        "import tensorflow as tf  # alternative pytorch\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split   #Train/validation/test Splitting\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import matplotlib.pyplot as plt # alternative seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "amr6E0ueum6W"
      },
      "outputs": [],
      "source": [
        "#fix random seeds so results are (reasonably) reproducible across runs\n",
        "np.random.seed(42)  #Seed Numpy's random no. generator\n",
        "tf.random.set_seed(42) #Seed tensorflow's random no. generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xVnacRjpvCY6"
      },
      "outputs": [],
      "source": [
        "#  2) Load & prepare the data\n",
        "iris = load_iris()   # Loads features (iris.data) and integers labels (iris.target)\n",
        "X=iris.data.astype(np.float32)  # Convert to float32 for TensorFlow efficiency /consistency\n",
        "y=iris.target.astype(np.int32) # Integer class IDs (0..2) suit sparse cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sxDErXOTwPU8"
      },
      "outputs": [],
      "source": [
        "# Split into train/test  while preserving original class ratios (stratify)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)#stratify is used to keep class balance\n",
        "# 20% test gives us an honest final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f45C3-CJw_GC"
      },
      "outputs": [],
      "source": [
        "# Scale features using ONLY the training set to avoid data leakage\n",
        "scaler = StandardScaler()  # Standadization helps optimization (balanced gradients)\n",
        "X_train = scaler.fit_transform(X_train) # Learn mean/std on train , then scale train\n",
        "X_test = scaler.transform(X_test) # Scale test with the same train statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Pmhgao0xn_s"
      },
      "outputs": [],
      "source": [
        "# Reshape features to a 1D \"signal\": (samples , length=4 , channels=1)\n",
        "X_train = X_train[...,np.newaxis]  # Now shape is (N_train ,4 ,1)\n",
        "X_test = X_test[...,np.newaxis]  # Now shape is (N_train ,4 ,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oM2ffwbEx5hq"
      },
      "outputs": [],
      "source": [
        "# Parts of one layer -  convolutional layer - extract features , cooling layer/operation- useful features selection , activation function\n",
        "\n",
        "#Define a 1D-CNN with EXACTLY 5 Conv layers\n",
        "#We use paddind=\"same\"  so length stays 4 throughtout ; kernel_size=2 captures local pairwise interactions.\n",
        "model = tf.keras.Sequential([         #Stack layers in order\n",
        "                             tf.keras.layers.Input(shape=(4,1)),# Expext sequence of length 4 with 1 channel\n",
        "                             tf.keras.layers.Conv1D(16, kernel_size=2, padding=\"same\", activation=\"relu\"), # Conv #1: few filters to start\n",
        "                             tf.keras.layers.Conv1D(32, kernel_size=2, padding=\"same\", activation=\"relu\"),# Conv #2: widen feature capacity\n",
        "                             tf.keras.layers.Conv1D(64, kernel_size=2, padding=\"same\", activation=\"relu\"),# Conv #3: deeper , richer features\n",
        "                             tf.keras.layers.Conv1D(64, kernel_size=2, padding=\"same\", activation=\"relu\"),# Conv #4: maintain depth\n",
        "                             tf.keras.layers.Conv1D(32, kernel_size=2, padding=\"same\", activation=\"relu\"),# Conv #5: taper down to reduce params\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),  #Collpse length  dimension by averaging channels (order-free)\n",
        "                             tf.keras.layers.Dense(16,activation=\"relu\"), # Small dense head to mix feature non linearly\n",
        "                             tf.keras.layers.Dense(3,activation=\"softmax\"), # Output probabilities for 3 Iris species\n",
        "                            ])# kernel - filter - predefined values - different for img , voice etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PYVEagbW25D5"
      },
      "outputs": [],
      "source": [
        "#Show a concise architecture summary to verify we indeed have 5 Conv layers\n",
        "model.summary() #Good sanity check for layer counts , shapes  , and parameter sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qmK64vvu6N2Z"
      },
      "outputs": [],
      "source": [
        "# === 4) Compile (choose optimizer, loss, and metrics) ========================\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),   # Adam is a robust default optimizer\n",
        "    loss='sparse_categorical_crossentropy',                   # Use integer labels ‚áí ‚Äúsparse_‚Äù CE\n",
        "    metrics=['accuracy']                                      # Track accuracy during training/eval\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "ybykiOzz7Zs0"
      },
      "outputs": [],
      "source": [
        "# Train with early stopping to avoid overfitting =======================\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=20, restore_best_weights=True\n",
        ")  # Stop when validation loss stalls; roll back to the best model\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1   # üëà shows training & validation accuracy/loss for every epoch\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UXwbEscC8VC-"
      },
      "outputs": [],
      "source": [
        "# === Plot training & validation curves =======================================\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jmIWRjI89Lc-"
      },
      "outputs": [],
      "source": [
        "# === 6) Evaluate & report ====================================================\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)   # Final unbiased test metrics\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")                           # Human-friendly accuracy readout\n",
        "\n",
        "y_prob = model.predict(X_test, verbose=0)                         # Predicted class probabilities\n",
        "y_pred = y_prob.argmax(axis=1)                                    # Convert probs ‚Üí predicted class IDs\n",
        "\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))    # See per-class confusions\n",
        "print(\"\\nClassification report:\\n\",                                # Precision/Recall/F1 per class\n",
        "      classification_report(y_test, y_pred, target_names=iris.target_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+o9Ib/WrYz+ZAhk3ONVr1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}